\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Measuring metadata quality}
\author{Péter Király}
\date{April 2019}

\begin{document}

\maketitle

\section{Abstract}

In the last 15 years different aspects of the metadata quality has been investigated. The researchers measured the established metrics on a variety of metadata collections. One common aspects of the majority of these research projects is that the tools they produce as a necessary side effect were not intended to reuse in other projects. This research, while focusing mainly on a specific metadata collection, Europeana, investigates such practical aspects of metadata quality measurement as reusability, reproducability, scalability and adaptability.

Europeana.eu -- the European digital platform for cultural heritage -- aggregates metadata describing 58 million cultural heritage objects from more than 3200 libraries, museums, archives and audiovisual archives across Europe. The collection is heterogeneous, the original nature and context of these records were different. In order to create effective services upon them we should know the strength and weakness or in other words the quality of these data. The need for quality of metadata is particularly motivated by its impact on user experience, information retrieval and data re-use in other contexts. The author proposes a method and an open source implementation to measure some structural features of these data, such as completeness, multilinguality, uniqueness, record patterns, to reveal quality issues.

One of the key goals of Europeana is to enable users to retrieve cultural heritage resources irrespective of their origin and the material’s metadata language. The presence of multilingual metadata descriptions is therefore essential for successful cross-language retrieval. Quantitatively determining Europeana’s crosslingual reach is a prerequisite for enhancing the quality of metadata in various languages. Capturing multilingual aspects of the data requires us to take into account the full lifecycle of data aggregation including data enhancement processes such as automatic data enrichment. Together with some members of Europeana Data Quality Committee the author presents an approach for assessing multilinguality as part of data quality dimensions, namely completeness, consistency, conformity and accessibility. The chapter describes the measures defined and implemented, and provide initial results and recommendations.

The next chapter -- investigating the applicability of the above mentioned approach -- describes the method and results of validation of 16 library catalogues. The format of the catalog record is Machine Readable Catalog (MARC21) which is the most popular metadata standards for describing books. The research investigates the structural features of the record and as a result finds and classifies different commonly found issues. The most frequent issue types are usage of undocumented schema elements, then improper values in places where a value should be taken from a dictionary, or should match to other strict requirements.

The next chapters describes the engineering aspects of the research. First, a short account of the structure of an extensible metadata quality assessment framework, which supports multiple metadata schemas, and is flexible enough to work with new schemas. The software has to be scalable to be able to process huge amount of metadata records within a reasonable time. Fundamental requirements that need to be considered during the design of such a software are i) the abstraction of the metadata schema (in the context of the measurement process), ii) how to address distinct parts within metadata records, iii) the workflow of the measurement, iv) a common and powerful interface for the individual metrics, and v) interoperability with Java and REST APIs. Second, is an investigation of the optimal parameter settings for a long running, standalone mode Apache Spark based, stateless process. It measures the effects of four different parameters and compares the application's behaviour in two different servers. The most important lessons learned in this experiment is that allocating more resource does not necessary imply better performance, moreover what we really need in an environment with limited and shared resources is a `good enough' state which politely let other processes run. To find the optimal settings it is suggested to pick up a smaller sample, which is similar to the full dataset in important features, and measure performance with different settings. The settings worth to check are number of cores, memory allocation, compression of the source files, and reading from different file systems (if they are available). As a source of ground truth Spark log, Spark event log, or measuring points inside the application can be used.

The final chapter explains future plans, the applicability of the method to other subdomains, such as Wikicite (the open citation data collection of Wikidata) and research data, and research collaborations with different cultural heritage institutions.

\end{document}
